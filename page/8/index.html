<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.1.1"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-logo.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-logo.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/themes/blue/pace-theme-minimal.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"maybeiscai.github.io",root:"/",scheme:"Mist",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:type" content="website"><meta property="og:title" content="智商为零的小白的博客"><meta property="og:url" content="https://maybeiscai.github.io/page/8/index.html"><meta property="og:site_name" content="智商为零的小白的博客"><meta property="og:description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="智商为零的小白"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://maybeiscai.github.io/page/8/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!0,isPost:!1,lang:"zh-CN"}</script><title>智商为零的小白的博客</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">智商为零的小白的博客</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content index posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://maybeiscai.github.io/posts/20211001010100.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211001010100.html" class="post-title-link" itemprop="url">Pytorch.torch.transpose</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-01 01:01:00" itemprop="dateCreated datePublished" datetime="2021-10-01T01:01:00+08:00">2021-10-01</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-20 22:37:28" itemprop="dateModified" datetime="2021-10-20T22:37:28+08:00">2021-10-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211001010100.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211001010100.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>939 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchtranspose"><a class="markdownIt-Anchor" href="#pytorchtorchtranspose"></a> Pytorch.torch.transpose</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.transpose(input, dim0, dim1) -&gt; Tensor</span><br><span class="line">    <span class="string">r&#x27;&#x27;&#x27;Returns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped.</span></span><br><span class="line"><span class="string">    The resulting out tensor shares its underlying storage with the input tensor, so changing the content of one would change the content of the other.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">        input (Tensor) - the input tensor.</span></span><br><span class="line"><span class="string">        dim0 (int) - the first dimension to be transposed</span></span><br><span class="line"><span class="string">        dim1 (int) - the second dimension to be transposed</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>transpose</code> 将 <code>input</code> 的 <code>dim0</code> 和 <code>dim1</code> 的元素对换位置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">6</span>).view(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[0, 1], </span></span><br><span class="line"><span class="string">        [2, 3], </span></span><br><span class="line"><span class="string">        [4, 5]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.transpose(x, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[0, 2, 4], </span></span><br><span class="line"><span class="string">        [1, 3, 5]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">x = torch.arange(<span class="number">8</span>).view(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 1],   </span></span><br><span class="line"><span class="string">         [2, 3]],  </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[4, 5],   </span></span><br><span class="line"><span class="string">         [6, 7]]]) </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.transpose(x, <span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 4],   </span></span><br><span class="line"><span class="string">         [2, 6]],  </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[1, 5],   </span></span><br><span class="line"><span class="string">         [3, 7]]]) </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://maybeiscai.github.io/posts/20211001010000.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211001010000.html" class="post-title-link" itemprop="url">Pytorch.torch.tile</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-01 01:00:00" itemprop="dateCreated datePublished" datetime="2021-10-01T01:00:00+08:00">2021-10-01</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-20 22:37:16" itemprop="dateModified" datetime="2021-10-20T22:37:16+08:00">2021-10-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211001010000.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211001010000.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.1k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchtile"><a class="markdownIt-Anchor" href="#pytorchtorchtile"></a> Pytorch.torch.tile</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">torch.tile(input, reps) -&gt; Tensor</span><br><span class="line">    <span class="string">r&#x27;&#x27;&#x27;Constructs a tensor by repeating the elements of input. The reps argument specifies the number of repetitions in each dimension.</span></span><br><span class="line"><span class="string">    If reps specifies fewer dimensions than input has, then ones are prepended to reps until all dimensions are specified. For example, if input has shape (8, 6, 4, 2) and reps is (2, 2), then reps is treated as (1, 1, 2, 2).</span></span><br><span class="line"><span class="string">    Analogously, if input has fewer dimensions than reps specifies, then input is treated as if it were unsqueezed at dimension zero until it has as many dimensions as reps specifies. For example, if input has shape (4, 2) and reps is (3, 3, 2, 2), then input is treated as if it had the shape (1, 1, 4, 2).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    NOTE</span></span><br><span class="line"><span class="string">        This function is similar to NumPy’s tile function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">        input (Tensor) - the tensor whose elements to repeat.</span></span><br><span class="line"><span class="string">        reps (tuple) - the number of repetitions per dimension.</span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>tile</code> 将重复元素以构造元素。如果 <code>input</code> 的维度高于 <code>reps</code>，则将 <code>reps</code> 高维视为 <code>1</code> 扩充到与 <code>input</code> 维度相同，如果 <code>input</code> 的维度低于 <code>reps</code>，则将 <code>input</code> 的高维视为 <code>1</code> 扩充到与 <code>reps</code> 维度相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">print(x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([1, 2, 3])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(x.tile((<span class="number">2</span>, )))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([1, 2, 3, 1, 2, 3])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([1, 2, 3])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">x = torch.arange(<span class="number">4</span>).view(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[0, 1],</span></span><br><span class="line"><span class="string">        [2, 3]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.tile(x, (<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[[0, 1, 0, 1],   </span></span><br><span class="line"><span class="string">          [2, 3, 2, 3],   </span></span><br><span class="line"><span class="string">          [0, 1, 0, 1],   </span></span><br><span class="line"><span class="string">          [2, 3, 2, 3]],  </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         [[0, 1, 0, 1],   </span></span><br><span class="line"><span class="string">          [2, 3, 2, 3],   </span></span><br><span class="line"><span class="string">          [0, 1, 0, 1],   </span></span><br><span class="line"><span class="string">          [2, 3, 2, 3]]], </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[[0, 1, 0, 1],   </span></span><br><span class="line"><span class="string">          [2, 3, 2, 3],   </span></span><br><span class="line"><span class="string">          [0, 1, 0, 1],   </span></span><br><span class="line"><span class="string">          [2, 3, 2, 3]],  </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         [[0, 1, 0, 1],   </span></span><br><span class="line"><span class="string">          [2, 3, 2, 3],   </span></span><br><span class="line"><span class="string">          [0, 1, 0, 1],   </span></span><br><span class="line"><span class="string">          [2, 3, 2, 3]]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">x = torch.arange(<span class="number">16</span>).view(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[[ 0,  1],</span></span><br><span class="line"><span class="string">          [ 2,  3]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         [[ 4,  5],</span></span><br><span class="line"><span class="string">          [ 6,  7]]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[[ 8,  9],</span></span><br><span class="line"><span class="string">          [10, 11]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         [[12, 13],</span></span><br><span class="line"><span class="string">          [14, 15]]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.tile(x, (<span class="number">3</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[[ 0,  1,  0,  1],</span></span><br><span class="line"><span class="string">          [ 2,  3,  2,  3],</span></span><br><span class="line"><span class="string">          [ 0,  1,  0,  1],</span></span><br><span class="line"><span class="string">          [ 2,  3,  2,  3],</span></span><br><span class="line"><span class="string">          [ 0,  1,  0,  1],</span></span><br><span class="line"><span class="string">          [ 2,  3,  2,  3]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         [[ 4,  5,  4,  5],</span></span><br><span class="line"><span class="string">          [ 6,  7,  6,  7],</span></span><br><span class="line"><span class="string">          [ 4,  5,  4,  5],</span></span><br><span class="line"><span class="string">          [ 6,  7,  6,  7],</span></span><br><span class="line"><span class="string">          [ 4,  5,  4,  5],</span></span><br><span class="line"><span class="string">          [ 6,  7,  6,  7]]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[[ 8,  9,  8,  9],</span></span><br><span class="line"><span class="string">          [10, 11, 10, 11],</span></span><br><span class="line"><span class="string">          [ 8,  9,  8,  9],</span></span><br><span class="line"><span class="string">          [10, 11, 10, 11],</span></span><br><span class="line"><span class="string">          [ 8,  9,  8,  9],</span></span><br><span class="line"><span class="string">          [10, 11, 10, 11]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         [[12, 13, 12, 13],</span></span><br><span class="line"><span class="string">          [14, 15, 14, 15],</span></span><br><span class="line"><span class="string">          [12, 13, 12, 13],</span></span><br><span class="line"><span class="string">          [14, 15, 14, 15],</span></span><br><span class="line"><span class="string">          [12, 13, 12, 13],</span></span><br><span class="line"><span class="string">          [14, 15, 14, 15]]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://maybeiscai.github.io/posts/20211001005900.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211001005900.html" class="post-title-link" itemprop="url">Pytorch.torch.tensor_split</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-01 00:59:00" itemprop="dateCreated datePublished" datetime="2021-10-01T00:59:00+08:00">2021-10-01</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-20 22:37:18" itemprop="dateModified" datetime="2021-10-20T22:37:18+08:00">2021-10-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211001005900.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211001005900.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.4k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchtensor_split"><a class="markdownIt-Anchor" href="#pytorchtorchtensor_split"></a> Pytorch.torch.tensor_split</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">torch.tensor_split(input, indices_or_sections, dim=0) -&gt; List of Tensors</span><br><span class="line">    <span class="string">r&#x27;&#x27;&#x27;Splits a tensor into multiple sub-tensors, all of which are views of input, along dimension dim according to the indices or number of sections specified by indices_or_sections. This function is based on NumPy’s numpy.array_split().</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">        input (Tensor) - the tensor to split</span></span><br><span class="line"><span class="string">        indices_or_sections (Tensor, int or list or tuple of python:ints) -</span></span><br><span class="line"><span class="string">            If indices_or_sections is an integer n or a zero dimensional long tensor with value n, input is split into n sections along dimension dim. If input is divisible by n along dimension dim, each section will be of equal size, input.size(dim) / n. If input is not divisible by n, the sizes of the first int(input.size(dim) % n) sections will have size int(input.size(dim) / n) + 1, and the rest will have size int(input.size(dim) / n).</span></span><br><span class="line"><span class="string">            If indices_or_sections is a list or tuple of ints, or a one-dimensional long tensor, then input is split along dimension dim at each of the indices in the list, tuple or tensor. For instance, indices_or_sections=[2, 3] and dim=0 would result in the tensors input[:2], input[2:3], and input[3:].</span></span><br><span class="line"><span class="string">            If indices_or_sections is a tensor, it must be a zero-dimensional or one-dimensional long tensor on the CPU.</span></span><br><span class="line"><span class="string">        dim (int, optional) - dimension along which to split the tensor. Default: 0</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>tensor_split</code> 将根据 <code>indices_or_sections</code> 和 <code>dim</code> 将 <code>input</code> 拆分，<code>dim</code> 为拆分操作所沿维度。对于 <code>indices_or_sections</code>，如果其为整数或零维张量，其数值为 <code>n</code>，则其将 <code>input</code> 沿 <code>dim</code> 均匀分为 <code>n</code> 份，若 <code>input.size(dim)</code> 不能整除 <code>n</code>，则前 <code>input.size(dim)%n</code> 的个数为 <code>int(input.size(dim)/n)+1</code>，其余的为 <code>int(input.size(dim)/n)</code>；如果 <code>indices_or_sections</code> 为 <code>list</code>，<code>tuple</code> 或一维张量，则将以 <code>indices</code> 进行拆分，如 <code>indices_or_sections=[2, 3]</code>，<code>dim=0</code>，则拆分后的张量为 <code>input[:2], input[2:3], input[3:]</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">8</span>)</span><br><span class="line">print(torch.tensor_split(x, <span class="number">3</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">x = torch.arange(<span class="number">7</span>)</span><br><span class="line">print(torch.tensor_split(x, torch.tensor(<span class="number">3</span>)))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([0, 1, 2]), tensor([3, 4]), tensor([5, 6]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.tensor_split(x, (<span class="number">1</span>, <span class="number">6</span>)))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([0]), tensor([1, 2, 3, 4, 5]), tensor([6]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">x = torch.arange(<span class="number">14</span>).reshape(<span class="number">2</span>, <span class="number">7</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[ 0,  1,  2,  3,  4,  5,  6],</span></span><br><span class="line"><span class="string">        [ 7,  8,  9, 10, 11, 12, 13]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.tensor_split(x, <span class="number">3</span>, dim=<span class="number">1</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([[0, 1, 2],</span></span><br><span class="line"><span class="string">        [7, 8, 9]]), tensor([[ 3,  4],</span></span><br><span class="line"><span class="string">        [10, 11]]), tensor([[ 5,  6],</span></span><br><span class="line"><span class="string">        [12, 13]]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.tensor_split(x, (<span class="number">1</span>, <span class="number">6</span>), dim=<span class="number">1</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([[0],</span></span><br><span class="line"><span class="string">        [7]]), tensor([[ 1,  2,  3,  4,  5],</span></span><br><span class="line"><span class="string">        [ 8,  9, 10, 11, 12]]), tensor([[ 6],</span></span><br><span class="line"><span class="string">        [13]]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://maybeiscai.github.io/posts/20211001005800.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211001005800.html" class="post-title-link" itemprop="url">Pytorch.torch.take</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-01 00:58:00" itemprop="dateCreated datePublished" datetime="2021-10-01T00:58:00+08:00">2021-10-01</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-12 22:20:38" itemprop="dateModified" datetime="2021-10-12T22:20:38+08:00">2021-10-12</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211001005800.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211001005800.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>493 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchtake"><a class="markdownIt-Anchor" href="#pytorchtorchtake"></a> Pytorch.torch.take</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">torch.take(input, index) -&gt; Tensor</span><br><span class="line">    <span class="string">r&#x27;&#x27;&#x27;Returns a new tensor with the elements of input at the given indices. The input tensor is treated as if it were viewed as a 1-D tensor. The result takes the same shape as the indices.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">        input (Tensor) – the input tensor.</span></span><br><span class="line"><span class="string">        index (LongTensor) – the indices into tensor</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>take</code> 将 <code>input</code> 是为一维并取出下标为 <code>index</code> 的张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.tensor([[<span class="number">4</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">print(torch.take(x, torch.tensor([<span class="number">0</span>, <span class="number">2</span>, <span class="number">5</span>])))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([4, 5, 8])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://maybeiscai.github.io/posts/20211001005700.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211001005700.html" class="post-title-link" itemprop="url">Pytorch.torch.t</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-01 00:57:00" itemprop="dateCreated datePublished" datetime="2021-10-01T00:57:00+08:00">2021-10-01</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-12 22:15:38" itemprop="dateModified" datetime="2021-10-12T22:15:38+08:00">2021-10-12</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211001005700.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211001005700.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>845 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorcht"><a class="markdownIt-Anchor" href="#pytorchtorcht"></a> Pytorch.torch.t</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">torch.t(input) -&gt; Tensor</span><br><span class="line">	<span class="string">r&#x27;&#x27;&#x27;Expects input to be &lt;= 2-D tensor and transposes dimensions 0 and 1.</span></span><br><span class="line"><span class="string">    0-D and 1-D tensors are returned as it is. When input is a 2-D tensor this is equivalent to transpose(input, 0, 1).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    	input (Tensor) – the input tensor.</span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>对于维度小于等于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">2</span></span></span></span> 的张量 <code>input</code>，若 <code>input</code> 为 <code>0-D</code> 或 <code>1-D</code>，则直接返回，若 <code>input</code> 为 <code>2-D</code>，则返回其转置。对于维度超过 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">2</span></span></span></span> 的张量将报错。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.randn(())</span><br><span class="line">print(x)</span><br><span class="line">print(torch.t(x))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor(1.2739)</span></span><br><span class="line"><span class="string">tensor(1.2739)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">x = torch.randn(<span class="number">3</span>)</span><br><span class="line">print(x)</span><br><span class="line">print(torch.t(x))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([ 0.3120, -1.2705,  0.7770])</span></span><br><span class="line"><span class="string">tensor([ 0.3120, -1.2705,  0.7770])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">print(x)</span><br><span class="line">print(torch.t(x))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[-0.4213,  0.7509,  0.5363],</span></span><br><span class="line"><span class="string">        [ 0.1409, -1.4335,  0.3886]])</span></span><br><span class="line"><span class="string">tensor([[-0.4213,  0.1409],</span></span><br><span class="line"><span class="string">        [ 0.7509, -1.4335],</span></span><br><span class="line"><span class="string">        [ 0.5363,  0.3886]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://maybeiscai.github.io/posts/20211001005600.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211001005600.html" class="post-title-link" itemprop="url">Pytorch.torch.swapdims</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-01 00:56:00" itemprop="dateCreated datePublished" datetime="2021-10-01T00:56:00+08:00">2021-10-01</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-12 22:05:36" itemprop="dateModified" datetime="2021-10-12T22:05:36+08:00">2021-10-12</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211001005600.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211001005600.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>522 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchswapdims"><a class="markdownIt-Anchor" href="#pytorchtorchswapdims"></a> Pytorch.torch.swapdims</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.swapdims(input, dim0, dim1) -&gt; Tensor</span><br><span class="line">	<span class="string">r&#x27;&#x27;&#x27;Alias for torch.transpose().</span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>swapdims</code> 方法为 <code>transpose</code> 的别名。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">8</span>).view(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 1],  </span></span><br><span class="line"><span class="string">         [2, 3]], </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[4, 5],  </span></span><br><span class="line"><span class="string">         [6, 7]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.swapdims(x, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 1], </span></span><br><span class="line"><span class="string">         [4, 5]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[2, 3],</span></span><br><span class="line"><span class="string">         [6, 7]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.swapdims(x, <span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 4],</span></span><br><span class="line"><span class="string">         [2, 6]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[1, 5],</span></span><br><span class="line"><span class="string">         [3, 7]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://maybeiscai.github.io/posts/20211001005500.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211001005500.html" class="post-title-link" itemprop="url">Pytorch.torch.swapaxes</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-01 00:55:00" itemprop="dateCreated datePublished" datetime="2021-10-01T00:55:00+08:00">2021-10-01</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-12 19:42:16" itemprop="dateModified" datetime="2021-10-12T19:42:16+08:00">2021-10-12</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211001005500.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211001005500.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>542 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchswapaxes"><a class="markdownIt-Anchor" href="#pytorchtorchswapaxes"></a> Pytorch.torch.swapaxes</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.swapaxes(input, axis0, axis1) -&gt; Tensor</span><br><span class="line">	<span class="string">r&#x27;&#x27;&#x27;Alias for torch.transpose().</span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>swapaxes</code> 将对换指定维度的元素。下图展示了将 <code>dim=0</code> 和 <code>dim=1</code> 交换的过程。</p><p><img src="/images/Pytorch/Pytorch.torch.swapaxes_figure_1.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">8</span>).view(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 1], </span></span><br><span class="line"><span class="string">         [2, 3]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[4, 5],</span></span><br><span class="line"><span class="string">         [6, 7]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.swapaxes(x, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 1],</span></span><br><span class="line"><span class="string">         [4, 5]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[2, 3],</span></span><br><span class="line"><span class="string">         [6, 7]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.swapaxes(x, <span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 4],</span></span><br><span class="line"><span class="string">         [2, 6]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[1, 5],</span></span><br><span class="line"><span class="string">         [3, 7]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://maybeiscai.github.io/posts/20211001005400.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211001005400.html" class="post-title-link" itemprop="url">Pytorch.torch.stack</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-01 00:54:00" itemprop="dateCreated datePublished" datetime="2021-10-01T00:54:00+08:00">2021-10-01</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-12 18:17:48" itemprop="dateModified" datetime="2021-10-12T18:17:48+08:00">2021-10-12</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211001005400.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211001005400.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>902 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchstack"><a class="markdownIt-Anchor" href="#pytorchtorchstack"></a> Pytorch.torch.stack</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">torch.stack(tensors, dim=0, out=None) -&gt; Tensor</span><br><span class="line">    <span class="string">r&#x27;&#x27;&#x27;Concatenates a sequence of tensors along a new dimension.</span></span><br><span class="line"><span class="string">    All tensors need to be of the same size.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">        tensors (sequence of Tensors) - sequence of tensors to concatenate</span></span><br><span class="line"><span class="string">        dim (int) - dimension to insert. Has to be between 0 and the number of dimensions of concatenated tensors (inclusive)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Keyword Arguments</span></span><br><span class="line"><span class="string">    	out (Tensor, optional) - the output tensor.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>stack</code> 在 <code>dim</code> 创建新的维度，并沿着这个维度拼接张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">a = torch.arange(<span class="number">4</span>).view((<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[0, 1], </span></span><br><span class="line"><span class="string">        [2, 3]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">b = torch.arange(<span class="number">4</span>, <span class="number">8</span>).view((<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">print(b)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[4, 5],</span></span><br><span class="line"><span class="string">        [6, 7]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.stack((a, b), dim=<span class="number">0</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 1],</span></span><br><span class="line"><span class="string">         [2, 3]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[4, 5],</span></span><br><span class="line"><span class="string">         [6, 7]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.stack((a, b), dim=<span class="number">1</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 1],</span></span><br><span class="line"><span class="string">         [4, 5]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[2, 3],</span></span><br><span class="line"><span class="string">         [6, 7]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://maybeiscai.github.io/posts/20211001005300.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211001005300.html" class="post-title-link" itemprop="url">Pytorch.torch.squeeze</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-01 00:53:00" itemprop="dateCreated datePublished" datetime="2021-10-01T00:53:00+08:00">2021-10-01</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-12 18:18:02" itemprop="dateModified" datetime="2021-10-12T18:18:02+08:00">2021-10-12</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211001005300.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211001005300.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>928 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchsqueeze"><a class="markdownIt-Anchor" href="#pytorchtorchsqueeze"></a> Pytorch.torch.squeeze</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.squeeze(input, dim=None, *, out=None) -&gt; Tensor</span><br><span class="line">    <span class="string">r&#x27;&#x27;&#x27;Returns a tensor with all the dimensions of input of size 1 removed.</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    	input (Tensor) - the input tensor.</span></span><br><span class="line"><span class="string">		dim (int, optional) - if given, the input will be squeezed only in this dimension</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Keyword Arguments</span></span><br><span class="line"><span class="string">    	out (Tensor, optional) - the output tensor.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>squeeze</code> 将在指定维度内移除维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 的那一维。如 <code>input</code> 的 <code>shape</code> 为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>A</mi><mo>×</mo><mn>1</mn><mo>×</mo><mi>B</mi><mo>×</mo><mi>C</mi><mo>×</mo><mn>1</mn><mo>×</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(A\times1\times B\times C\times 1\times D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.05017em">B</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="mclose">)</span></span></span></span>，则输出形状将为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>A</mi><mo>×</mo><mi>B</mi><mo>×</mo><mi>C</mi><mo>×</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(A\times B\times C\times D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.05017em">B</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="mclose">)</span></span></span></span>。</p><p>如果指定 <code>dim</code>，则仅在 <code>dim</code> 维进行上述操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.zeros(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">print(x.size())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.Size([2, 1, 2, 1, 2])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">y = torch.squeeze(x)</span><br><span class="line">print(y.size())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.Size([2, 2, 2])      </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">y = torch.squeeze(x, <span class="number">0</span>)</span><br><span class="line">print(y.size())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.Size([2, 1, 2, 1, 2])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">y = torch.squeeze(x, <span class="number">1</span>)</span><br><span class="line">print(y.size())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.Size([2, 2, 1, 2])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://maybeiscai.github.io/posts/20211001005200.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211001005200.html" class="post-title-link" itemprop="url">Pytorch.torch.split</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-01 00:52:00" itemprop="dateCreated datePublished" datetime="2021-10-01T00:52:00+08:00">2021-10-01</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-12 18:17:46" itemprop="dateModified" datetime="2021-10-12T18:17:46+08:00">2021-10-12</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211001005200.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211001005200.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.1k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchsplit"><a class="markdownIt-Anchor" href="#pytorchtorchsplit"></a> Pytorch.torch.split</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">torch.split(tensor, split_size_or_sections, dim=<span class="number">0</span>)</span><br><span class="line">    <span class="string">r&#x27;&#x27;&#x27;Splits the tensor into chunks. Each chunk is a view of the original tensor.</span></span><br><span class="line"><span class="string">        If split_size_or_sections is an integer type, then tensor will be split into equally sized chunks (if possible). Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by split_size.</span></span><br><span class="line"><span class="string">        If split_size_or_sections is a list, then tensor will be split into len(split_size_or_sections) chunks with sizes in dim according to split_size_or_sections.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">        tensor (Tensor) - tensor to split.</span></span><br><span class="line"><span class="string">        split_size_or_sections (int) or (list(int)) - size of a single chunk or list of sizes for each chunk</span></span><br><span class="line"><span class="string">        dim (int) - dimension along which to split the tensor.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>split</code> 将沿着指定维度按照指定大小拆分张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">a = torch.arange(<span class="number">10</span>).reshape(<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[0, 1],</span></span><br><span class="line"><span class="string">        [2, 3],</span></span><br><span class="line"><span class="string">        [4, 5],</span></span><br><span class="line"><span class="string">        [6, 7],</span></span><br><span class="line"><span class="string">        [8, 9]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.split(a, <span class="number">2</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([[0, 1],</span></span><br><span class="line"><span class="string">        [2, 3]]), tensor([[4, 5],</span></span><br><span class="line"><span class="string">        [6, 7]]), tensor([[8, 9]]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(torch.split(a, [<span class="number">2</span>, <span class="number">3</span>]))  <span class="comment"># a[0:0+2], a[0+2:0+2+3]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([[0, 1],</span></span><br><span class="line"><span class="string">        [2, 3]]), tensor([[4, 5],</span></span><br><span class="line"><span class="string">        [6, 7],</span></span><br><span class="line"><span class="string">        [8, 9]]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><nav class="pagination"><a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/48/">48</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right" aria-label="下一页"></i></a></nav></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="智商为零的小白" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">智商为零的小白</p><div class="site-description" itemprop="description">生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">472</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">32</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">91</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/Maybeiscai" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Maybeiscai" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:1979938740@qq.com" title="E-Mail → mailto:1979938740@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">智商为零的小白</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">1.4m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">20:47 小时</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css"><script>NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'rxJydM3QVoypB9apkSU3e9ML-gzGzoHsz',
      appKey     : 'NqXT8ScfaD1udoMiPk3NQ6MF',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});</script><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><canvas class="fireworks" style="position:fixed;left:0;top:0;z-index:1;pointer-events:none"></canvas><script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script><script type="text/javascript" src="/js/src/fireworks.js"></script></body></html>