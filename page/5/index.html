<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.1.1"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-logo.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-logo.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/themes/blue/pace-theme-minimal.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"koumudai.github.io",root:"/",scheme:"Mist",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:type" content="website"><meta property="og:title" content="智商为零的小白的博客"><meta property="og:url" content="https://koumudai.github.io/page/5/index.html"><meta property="og:site_name" content="智商为零的小白的博客"><meta property="og:description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="智商为零的小白"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://koumudai.github.io/page/5/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!0,isPost:!1,lang:"zh-CN"}</script><title>智商为零的小白的博客</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">智商为零的小白的博客</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content index posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://koumudai.github.io/posts/20211002001400.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001400.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.Resize</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:14:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:14:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:24:06" itemprop="dateModified" datetime="2021-10-27T09:24:06+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001400.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001400.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsresize"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsresize"></a> Pytorch.torchvision.transforms.Resize</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Resize</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Resize the input image to the given size.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    warning:</span></span><br><span class="line"><span class="string">        The output image might be different depending on its type: when downsampling, the interpolation of PIL images and tensors is slightly different, because PIL applies antialiasing. This may lead to significant differences  in the performance of a network. Therefore, it is preferable to train and serve a model with the same input types.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        size (sequence or int): Desired output size. If size is a sequence like (h, w), output size will be matched to this. If size is an int, smaller edge of the image will be matched to this number. i.e, if height &gt; width, then image will be rescaled to (size * height / width, size).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	note:</span></span><br><span class="line"><span class="string">		In torchscript mode size as single int is not supported, use a sequence of length 1: ``[size, ]``.</span></span><br><span class="line"><span class="string">        interpolation (InterpolationMode): Desired interpolation enum defined by :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.BILINEAR``. If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` and ``InterpolationMode.BICUBIC`` are supported. For backward compatibility integer values (e.g. ``PIL.Image.NEAREST``) are still acceptable.</span></span><br><span class="line"><span class="string">        max_size (int, optional): The maximum allowed for the longer edge of the resized image: if the longer edge of the image is greater than ``max_size`` after being resized according to ``size``, then the image is resized again so that the longer edge is equal to ``max_size``. As a result, ``size`` might be overruled, i.e the smaller edge may be shorter than ``size``. This is only supported if ``size`` is an int (or a sequence of length 1 in torchscript mode).</span></span><br><span class="line"><span class="string">        antialias (bool, optional): antialias flag. If ``img`` is PIL Image, the flag is ignored and anti-alias is always used. If ``img`` is Tensor, the flag is False by default and can be set True for ``InterpolationMode.BILINEAR`` only mode.</span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>Resize</code> 将对输入图片进行放缩，若 <code>size</code> 为 <code>(h, w)</code>，则输出大小为 <code>(h, w)</code>，若 <code>size</code> 为 <code>int</code> 类型，则表示短边为 <code>size</code>，长边将进行放缩，例如 <code>h &gt; w</code> 时，将缩放为 <code>(size * h / w, size)</code>。如果 <code>max_size</code> 为 <code>int</code> 类型，则表示将长放缩后的图片再等比例放缩，使得长边为 <code>max_size</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">150</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">15</span>, <span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9],</span></span><br><span class="line"><span class="string">         [ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19],</span></span><br><span class="line"><span class="string">         [ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29],</span></span><br><span class="line"><span class="string">         [ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39],</span></span><br><span class="line"><span class="string">         [ 40,  41,  42,  43,  44,  45,  46,  47,  48,  49],</span></span><br><span class="line"><span class="string">         [ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59],</span></span><br><span class="line"><span class="string">         [ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69],</span></span><br><span class="line"><span class="string">         [ 70,  71,  72,  73,  74,  75,  76,  77,  78,  79],</span></span><br><span class="line"><span class="string">         [ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89],</span></span><br><span class="line"><span class="string">         [ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99],</span></span><br><span class="line"><span class="string">         [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],</span></span><br><span class="line"><span class="string">         [110, 111, 112, 113, 114, 115, 116, 117, 118, 119],</span></span><br><span class="line"><span class="string">         [120, 121, 122, 123, 124, 125, 126, 127, 128, 129],</span></span><br><span class="line"><span class="string">         [130, 131, 132, 133, 134, 135, 136, 137, 138, 139],</span></span><br><span class="line"><span class="string">         [140, 141, 142, 143, 144, 145, 146, 147, 148, 149]]],</span></span><br><span class="line"><span class="string">       dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.Resize((<span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[  8,   9,  10,  11,  13,  14,  15,  16],</span></span><br><span class="line"><span class="string">         [ 33,  34,  35,  36,  38,  39,  40,  41],</span></span><br><span class="line"><span class="string">         [ 58,  59,  60,  61,  63,  64,  65,  66],</span></span><br><span class="line"><span class="string">         [ 83,  84,  85,  86,  88,  89,  90,  91],</span></span><br><span class="line"><span class="string">         [108, 109, 110, 111, 113, 114, 115, 116],</span></span><br><span class="line"><span class="string">         [133, 134, 135, 136, 138, 139, 140, 141]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.Resize(<span class="number">6</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[  4,   5,   7,   9,  10,  12],</span></span><br><span class="line"><span class="string">         [ 20,  22,  24,  25,  27,  29],</span></span><br><span class="line"><span class="string">         [ 37,  39,  40,  42,  44,  45],</span></span><br><span class="line"><span class="string">         [ 54,  55,  57,  59,  60,  62],</span></span><br><span class="line"><span class="string">         [ 70,  72,  74,  75,  77,  79],</span></span><br><span class="line"><span class="string">         [ 87,  89,  90,  92,  94,  95],</span></span><br><span class="line"><span class="string">         [104, 105, 107, 109, 110, 112],</span></span><br><span class="line"><span class="string">         [120, 122, 124, 125, 127, 129],</span></span><br><span class="line"><span class="string">         [137, 139, 140, 142, 144, 145]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.Resize(<span class="number">6</span>, max_size=<span class="number">8</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[  5,   7,   9,  11,  13],</span></span><br><span class="line"><span class="string">         [ 24,  26,  28,  30,  32],</span></span><br><span class="line"><span class="string">         [ 42,  44,  46,  48,  50],</span></span><br><span class="line"><span class="string">         [ 61,  63,  65,  67,  69],</span></span><br><span class="line"><span class="string">         [ 80,  82,  84,  86,  88],</span></span><br><span class="line"><span class="string">         [ 99, 101, 103, 105, 107],</span></span><br><span class="line"><span class="string">         [117, 119, 121, 123, 125],</span></span><br><span class="line"><span class="string">         [136, 138, 140, 142, 144]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://koumudai.github.io/posts/20211002001300.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001300.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.RandomRotation</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:13:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:13:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:23:20" itemprop="dateModified" datetime="2021-10-27T09:23:20+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001300.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001300.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.6k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsrandomrotation"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsrandomrotation"></a> Pytorch.torchvision.transforms.RandomRotation</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomRotation</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Rotate the image by angle.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        degrees (sequence or number): Range of degrees to select from. If degrees is a number instead of sequence like (min, max), the range of degrees will be (-degrees, +degrees).</span></span><br><span class="line"><span class="string">        interpolation (InterpolationMode): Desired interpolation enum defined by :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.NEAREST``. If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported. For backward compatibility integer values (e.g. ``PIL.Image.NEAREST``) are still acceptable.</span></span><br><span class="line"><span class="string">        expand (bool, optional): Optional expansion flag. If true, expands the output to make it large enough to hold the entire rotated image. If false or omitted, make the output image the same size as the input image. Note that the expand flag assumes rotation around the center and no translation.</span></span><br><span class="line"><span class="string">        center (sequence, optional): Optional center of rotation, (x, y). Origin is the upper left corner. Default is the center of the image.</span></span><br><span class="line"><span class="string">        fill (sequence or number): Pixel fill value for the area outside the rotated image. Default is ``0``. If given a number, the value is used for all bands respectively.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>RandomRotation</code> 将输入图像随机旋转。</p><p>参数：</p><ul><li><code>degrees</code>：表示旋转的角度的最小值和最大值，若为一个数值，则最小值为 <code>-degrees</code>，最大值为 <code>+degrees</code>。</li><li><code>interpolation</code>：表示插值模式。</li><li><code>center</code>：表示旋转中心。</li><li><code>fill</code>：表示填充元素。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">100</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomRotation(degrees=(<span class="number">10</span>, <span class="number">20</span>), center=(<span class="number">1</span>, <span class="number">1</span>), fill=<span class="number">255</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[  0,   1,   2,  13,  14,  15,  26,  27,  28,  29],</span></span><br><span class="line"><span class="string">         [ 10,  11,  12,  23,  24,  25,  26,  37,  38,  39],</span></span><br><span class="line"><span class="string">         [ 20,  21,  22,  32,  33,  34,  35,  46,  47,  48],</span></span><br><span class="line"><span class="string">         [255,  30,  31,  42,  43,  44,  45,  56,  57,  58],</span></span><br><span class="line"><span class="string">         [255,  40,  41,  52,  53,  54,  55,  66,  67,  68],</span></span><br><span class="line"><span class="string">         [255,  50,  51,  62,  63,  64,  65,  76,  76,  77],</span></span><br><span class="line"><span class="string">         [255, 255,  60,  61,  72,  73,  74,  85,  86,  87],</span></span><br><span class="line"><span class="string">         [255, 255,  70,  71,  82,  83,  84,  95,  96,  97],</span></span><br><span class="line"><span class="string">         [255, 255,  80,  81,  92,  93,  94,  95, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255,  90,  91, 255, 255, 255, 255, 255, 255]]],</span></span><br><span class="line"><span class="string">       dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://koumudai.github.io/posts/20211002001200.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001200.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.RandomVerticalFlip</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:12:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:12:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:23:46" itemprop="dateModified" datetime="2021-10-27T09:23:46+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001200.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001200.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.4k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsrandomverticalflip"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsrandomverticalflip"></a> Pytorch.torchvision.transforms.RandomVerticalFlip</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TenCrop</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop the given image into four corners and the central crop plus the flipped version of these (horizontal flipping is used by default). If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note:</span></span><br><span class="line"><span class="string">         This transform returns a tuple of images and there may be a mismatch in the number of inputs and targets your Dataset returns. See below for an example of how to deal with this.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        size (sequence or int): Desired output size of the crop. If size is an int instead of sequence like (h, w), a square crop (size, size) is made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).</span></span><br><span class="line"><span class="string">        vertical_flip (bool): Use vertical flipping instead of horizontal</span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>RandomHorizontalFlip</code> 将以概率 <code>p</code> 对图片进行垂直翻转。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">16</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [ 8,  9, 10, 11],</span></span><br><span class="line"><span class="string">         [12, 13, 14, 15]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomVerticalFlip(p=<span class="number">0.6</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[12, 13, 14, 15],</span></span><br><span class="line"><span class="string">         [ 8,  9, 10, 11],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [ 0,  1,  2,  3]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://koumudai.github.io/posts/20211002001100.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001100.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.RandomHorizontalFlip</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:11:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:11:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:30:16" itemprop="dateModified" datetime="2021-10-27T09:30:16+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001100.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001100.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.1k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsrandomhorizontalflip"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsrandomhorizontalflip"></a> Pytorch.torchvision.transforms.RandomHorizontalFlip</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomHorizontalFlip</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Horizontally flip the given image randomly with a given probability.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        p (float): probability of the image being flipped. Default value is 0.5</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>RandomHorizontalFlip</code> 将以概率 <code>p</code> 对图片进行水平翻转。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">16</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [ 8,  9, 10, 11],</span></span><br><span class="line"><span class="string">         [12, 13, 14, 15]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomHorizontalFlip(p=<span class="number">0.6</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 3,  2,  1,  0],</span></span><br><span class="line"><span class="string">         [ 7,  6,  5,  4],</span></span><br><span class="line"><span class="string">         [11, 10,  9,  8],</span></span><br><span class="line"><span class="string">         [15, 14, 13, 12]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://koumudai.github.io/posts/20211002001000.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001000.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.TenCrop</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:10:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:10:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:24:26" itemprop="dateModified" datetime="2021-10-27T09:24:26+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001000.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001000.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>5k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>5 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformstencrop"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformstencrop"></a> Pytorch.torchvision.transforms.TenCrop</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TenCrop</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop the given image into four corners and the central crop plus the flipped version of these (horizontal flipping is used by default). If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note:</span></span><br><span class="line"><span class="string">         This transform returns a tuple of images and there may be a mismatch in the number of inputs and targets your Dataset returns. See below for an example of how to deal with this.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        size (sequence or int): Desired output size of the crop. If size is an int instead of sequence like (h, w), a square crop (size, size) is made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).</span></span><br><span class="line"><span class="string">        vertical_flip (bool): Use vertical flipping instead of horizontal</span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>TenCrop</code> 将对图片进行裁剪并获得十张图片，裁剪方式为：左上角、右上角、左下角、右下角和中心的裁剪，然后将裁剪后的图片进行翻转（可以通过设置 <code>vertical_flip</code> 来选择是水平翻转还是垂直翻转）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">100</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.TenCrop(<span class="number">6</span>)</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> t(a):</span><br><span class="line">    print(e)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[ 4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[22, 23, 24, 25, 26, 27],</span></span><br><span class="line"><span class="string">         [32, 33, 34, 35, 36, 37],</span></span><br><span class="line"><span class="string">         [42, 43, 44, 45, 46, 47],</span></span><br><span class="line"><span class="string">         [52, 53, 54, 55, 56, 57],</span></span><br><span class="line"><span class="string">         [62, 63, 64, 65, 66, 67],</span></span><br><span class="line"><span class="string">         [72, 73, 74, 75, 76, 77]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[ 9,  8,  7,  6,  5,  4],</span></span><br><span class="line"><span class="string">         [19, 18, 17, 16, 15, 14],</span></span><br><span class="line"><span class="string">         [29, 28, 27, 26, 25, 24],</span></span><br><span class="line"><span class="string">         [39, 38, 37, 36, 35, 34],</span></span><br><span class="line"><span class="string">         [49, 48, 47, 46, 45, 44],</span></span><br><span class="line"><span class="string">         [59, 58, 57, 56, 55, 54]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[ 5,  4,  3,  2,  1,  0],</span></span><br><span class="line"><span class="string">         [15, 14, 13, 12, 11, 10],</span></span><br><span class="line"><span class="string">         [25, 24, 23, 22, 21, 20],</span></span><br><span class="line"><span class="string">         [35, 34, 33, 32, 31, 30],</span></span><br><span class="line"><span class="string">         [45, 44, 43, 42, 41, 40],</span></span><br><span class="line"><span class="string">         [55, 54, 53, 52, 51, 50]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[49, 48, 47, 46, 45, 44],</span></span><br><span class="line"><span class="string">         [59, 58, 57, 56, 55, 54],</span></span><br><span class="line"><span class="string">         [69, 68, 67, 66, 65, 64],</span></span><br><span class="line"><span class="string">         [79, 78, 77, 76, 75, 74],</span></span><br><span class="line"><span class="string">         [89, 88, 87, 86, 85, 84],</span></span><br><span class="line"><span class="string">         [99, 98, 97, 96, 95, 94]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[45, 44, 43, 42, 41, 40],</span></span><br><span class="line"><span class="string">         [55, 54, 53, 52, 51, 50],</span></span><br><span class="line"><span class="string">         [65, 64, 63, 62, 61, 60],</span></span><br><span class="line"><span class="string">         [75, 74, 73, 72, 71, 70],</span></span><br><span class="line"><span class="string">         [85, 84, 83, 82, 81, 80],</span></span><br><span class="line"><span class="string">         [95, 94, 93, 92, 91, 90]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[27, 26, 25, 24, 23, 22],</span></span><br><span class="line"><span class="string">         [37, 36, 35, 34, 33, 32],</span></span><br><span class="line"><span class="string">         [47, 46, 45, 44, 43, 42],</span></span><br><span class="line"><span class="string">         [57, 56, 55, 54, 53, 52],</span></span><br><span class="line"><span class="string">         [67, 66, 65, 64, 63, 62],</span></span><br><span class="line"><span class="string">         [77, 76, 75, 74, 73, 72]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(<span class="string">&#x27;--&#x27;</span> * <span class="number">10</span>)</span><br><span class="line">t = transforms.TenCrop(<span class="number">6</span>, vertical_flip=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> t(a):</span><br><span class="line">    print(e)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[ 4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[22, 23, 24, 25, 26, 27],</span></span><br><span class="line"><span class="string">         [32, 33, 34, 35, 36, 37],</span></span><br><span class="line"><span class="string">         [42, 43, 44, 45, 46, 47],</span></span><br><span class="line"><span class="string">         [52, 53, 54, 55, 56, 57],</span></span><br><span class="line"><span class="string">         [62, 63, 64, 65, 66, 67],</span></span><br><span class="line"><span class="string">         [72, 73, 74, 75, 76, 77]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[90, 91, 92, 93, 94, 95],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[94, 95, 96, 97, 98, 99],</span></span><br><span class="line"><span class="string">         [84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [44, 45, 46, 47, 48, 49]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[50, 51, 52, 53, 54, 55],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15],</span></span><br><span class="line"><span class="string">         [ 0,  1,  2,  3,  4,  5]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7,  8,  9]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[72, 73, 74, 75, 76, 77],</span></span><br><span class="line"><span class="string">         [62, 63, 64, 65, 66, 67],</span></span><br><span class="line"><span class="string">         [52, 53, 54, 55, 56, 57],</span></span><br><span class="line"><span class="string">         [42, 43, 44, 45, 46, 47],</span></span><br><span class="line"><span class="string">         [32, 33, 34, 35, 36, 37],</span></span><br><span class="line"><span class="string">         [22, 23, 24, 25, 26, 27]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://koumudai.github.io/posts/20211002000900.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000900.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.FiveCrop</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:09:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:09:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:17:14" itemprop="dateModified" datetime="2021-10-27T09:17:14+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000900.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000900.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.3k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsfivecrop"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsfivecrop"></a> Pytorch.torchvision.transforms.FiveCrop</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FiveCrop</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop the given image into four corners and the central crop.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note:</span></span><br><span class="line"><span class="string">         This transform returns a tuple of images and there may be a mismatch in the number of inputs and targets your Dataset returns. See below for an example of how to deal with this.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">         size (sequence or int): Desired output size of the crop. If size is an ``int`` instead of sequence like (h, w), a square crop of size (size, size) is made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>FiveCrop</code> 将对图片进行裁剪并获得五张图片，裁剪方式为：左上角、右上角、左下角、右下角和中心的裁剪。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">100</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.FiveCrop(<span class="number">6</span>)</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> t(a):</span><br><span class="line">    print(e)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[ 4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[22, 23, 24, 25, 26, 27],</span></span><br><span class="line"><span class="string">         [32, 33, 34, 35, 36, 37],</span></span><br><span class="line"><span class="string">         [42, 43, 44, 45, 46, 47],</span></span><br><span class="line"><span class="string">         [52, 53, 54, 55, 56, 57],</span></span><br><span class="line"><span class="string">         [62, 63, 64, 65, 66, 67],</span></span><br><span class="line"><span class="string">         [72, 73, 74, 75, 76, 77]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://koumudai.github.io/posts/20211002000800.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000800.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.RandomResizedCrop</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:08:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:08:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:23:08" itemprop="dateModified" datetime="2021-10-27T09:23:08+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000800.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000800.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.5k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsrandomresizedcrop"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsrandomresizedcrop"></a> Pytorch.torchvision.transforms.RandomResizedCrop</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomResizedCrop</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop a random portion of image and resize it to a given size.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string">	A crop of the original image is made: the crop has a random area (H * W) and a random aspect ratio. This crop is finally resized to the given size. This is popularly used to train the Inception networks.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	Args:</span></span><br><span class="line"><span class="string">        size (int or sequence): expected output size of the crop, for each edge. If size is an int instead of sequence like (h, w), a square output size ``(size, size)`` is made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	note:</span></span><br><span class="line"><span class="string">		In torchscript mode size as single int is not supported, use a sequence of length 1: ``[size, ]``.</span></span><br><span class="line"><span class="string">        scale (tuple of float): Specifies the lower and upper bounds for the random area of the crop, before resizing. The scale is defined with respect to the area of the original image.</span></span><br><span class="line"><span class="string">        ratio (tuple of float): lower and upper bounds for the random aspect ratio of the crop, before resizing.</span></span><br><span class="line"><span class="string">        interpolation (InterpolationMode): Desired interpolation enum defined by :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.BILINEAR``. If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` and ``InterpolationMode.BICUBIC`` are supported. For backward compatibility integer values (e.g. ``PIL.Image.NEAREST``) are still acceptable.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>RandomResizedCrop</code> 将输入图像随机裁剪为不同的大小和宽高比，然后将裁剪后的图像放缩为输出大小。</p><p>参数：</p><ul><li><code>size</code>：表示输出的大小，若 <code>size</code> 为 <code>int</code> 值，则输出的大小为 <code>(size, size)</code>，若 <code>size</code> 为 <code>(h, w)</code>，则输出的大小为 <code>(h, w)</code>。</li><li><code>scale</code>：表示裁剪的图片相对于原始图片的比例的最小值和最大值。</li><li><code>ratio</code>：表示裁剪的图片相对于原始图片的高宽比的最小值和最大值。</li><li><code>interpolation</code>：表示插值的模式。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">16</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [ 8,  9, 10, 11],</span></span><br><span class="line"><span class="string">         [12, 13, 14, 15]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomResizedCrop(<span class="number">10</span>, scale=(<span class="number">0.1</span>, <span class="number">1</span>), ratio=(<span class="number">0.5</span>, <span class="number">2</span>))</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 1,  1,  1,  2,  2,  2,  2,  3,  3,  3],</span></span><br><span class="line"><span class="string">         [ 1,  1,  2,  2,  2,  3,  3,  3,  3,  3],</span></span><br><span class="line"><span class="string">         [ 3,  3,  3,  4,  4,  4,  4,  5,  5,  5],</span></span><br><span class="line"><span class="string">         [ 5,  5,  5,  5,  5,  6,  6,  6,  7,  7],</span></span><br><span class="line"><span class="string">         [ 6,  6,  6,  7,  7,  7,  8,  8,  8,  8],</span></span><br><span class="line"><span class="string">         [ 8,  8,  8,  8,  9,  9,  9, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [ 9,  9, 10, 10, 10, 11, 11, 11, 11, 11],</span></span><br><span class="line"><span class="string">         [11, 11, 11, 12, 12, 12, 12, 13, 13, 13],</span></span><br><span class="line"><span class="string">         [13, 13, 13, 13, 13, 14, 14, 14, 15, 15],</span></span><br><span class="line"><span class="string">         [13, 13, 13, 14, 14, 14, 14, 15, 15, 15]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://koumudai.github.io/posts/20211002000700.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000700.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.CenterCrop</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:07:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:07:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:16:16" itemprop="dateModified" datetime="2021-10-27T09:16:16+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000700.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000700.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.3k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformscentercrop"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformscentercrop"></a> Pytorch.torchvision.transforms.CenterCrop</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">center_crop</span>(<span class="params">img: Tensor, output_size: List[int]</span>) -&gt; Tensor:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crops the given image at the center.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected</span></span><br><span class="line"><span class="string">    to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions.</span></span><br><span class="line"><span class="string">    If image size is smaller than output size along any edge, image is padded with 0 and then center cropped.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        img (PIL Image or Tensor): Image to be cropped.</span></span><br><span class="line"><span class="string">        output_size (sequence or int): (height, width) of the crop box. If int or sequence with single int,</span></span><br><span class="line"><span class="string">            it is used for both directions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        PIL Image or Tensor: Cropped image.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>CenterCrop</code> 将根据给定的 <code>size</code> 从中心裁剪，若图片大小小于输出大小，则将填充 <code>0</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">20</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.CenterCrop(<span class="number">6</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  0,  0,  0,  0,  0],</span></span><br><span class="line"><span class="string">         [ 0,  0,  0,  0,  0,  0],</span></span><br><span class="line"><span class="string">         [ 2,  3,  4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [12, 13, 14, 15, 16, 17],</span></span><br><span class="line"><span class="string">         [ 0,  0,  0,  0,  0,  0],</span></span><br><span class="line"><span class="string">         [ 0,  0,  0,  0,  0,  0]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://koumudai.github.io/posts/20211002000600.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000600.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.RandomCrop</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:06:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:06:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:19:50" itemprop="dateModified" datetime="2021-10-27T09:19:50+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000600.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000600.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>4.3k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsrandomcrop"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsrandomcrop"></a> Pytorch.torchvision.transforms.RandomCrop</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomCrop</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop the given image at a random location.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions, but if non-constant padding is used, the input is expected to have at most 2 leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        size (sequence or int): Desired output size of the crop. If size is an int instead of sequence like (h, w), a square crop (size, size) is made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).</span></span><br><span class="line"><span class="string">        padding (int or sequence, optional): Optional padding on each border of the image. Default is None. If a single int is provided this is used to pad all borders. If sequence of length 2 is provided this is the padding on left/right and top/bottom respectively. If a sequence of length 4 is provided  this is the padding for the left, top, right and bottom borders respectively.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    note:</span></span><br><span class="line"><span class="string">        In torchscript mode padding as single int is not supported, use a sequence of length 1: ``[padding, ]``.</span></span><br><span class="line"><span class="string">        pad_if_needed (boolean): It will pad the image if smaller than the desired size to avoid raising an exception. Since cropping is done after padding, the padding seems to be done at a random offset.</span></span><br><span class="line"><span class="string">        fill (number or str or tuple): Pixel fill value for constant fill. Default is 0. If a tuple of length 3, it is used to fill R, G, B channels respectively. This value is only used when the padding_mode is constant. Only number is supported for torch Tensor. Only int or str or tuple value is supported for PIL Image.</span></span><br><span class="line"><span class="string">        padding_mode (str): Type of padding. Should be: constant, edge, reflect or symmetric. Default is constant.</span></span><br><span class="line"><span class="string">            - constant: pads with a constant value, this value is specified with fill</span></span><br><span class="line"><span class="string">            - edge: pads with the last value at the edge of the image. If input a 5D torch Tensor, the last 3 dimensions will be padded instead of the last 2</span></span><br><span class="line"><span class="string">            - reflect: pads with reflection of image without repeating the last value on the edge. For example, padding [1, 2, 3, 4] with 2 elements on both sides in reflect mode will result in [3, 2, 1, 2, 3, 4, 3, 2]</span></span><br><span class="line"><span class="string">            - symmetric: pads with reflection of image repeating the last value on the edge. For example, padding [1, 2, 3, 4] with 2 elements on both sides in symmetric mode will result in [2, 1, 1, 2, 3, 4, 4, 3]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>RandomCrop</code> 将对原始图片进行随机裁剪，要求被处理的 <code>tensor</code> 的形状为 <code>[..., H, W]</code>。</p><p>参数：</p><ul><li><code>size</code>：表示输出的大小，若 <code>size</code> 为 <code>int</code> 值，则输出的大小为 <code>(size, size)</code>，若 <code>size</code> 为 <code>(h, w)</code>，则输出的大小为 <code>(h, w)</code>。</li><li><code>padding</code>：表示填充情况，若 <code>padding</code> 为 <code>int</code> 值，则在上下左右都填充 <code>padding</code>，若 <code>padding</code> 为长度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">2</span></span></span></span> 的序列，则左右填充 <code>padding[0]</code>，上下填充 <code>padding[1]</code>，若 <code>padding</code> 为长度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">4</span></span></span></span> 的序列，则左上右下分别填充为 <code>padding[0], padding[1], padding[2], padding[3]</code>。注意 <code>padding</code> 为 <code>int</code> 在 <code>torchscript</code> 模式下不支持，建议使用长度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 的序列 <code>[padding, ]</code>。</li><li><code>pad_if_needed</code>：是否在经过 <code>padding</code> 后的图片大小小于输出大小时，对 <code>padding</code> 后的图片进行填充，若为是，则设 <code>padding</code> 后的图片的宽高为 <code>width, height</code>，输出的宽高为 <code>size[1], size[0]</code>，则左右填充 <code>size[1]-weight</code>，上下填充 <code>size[0]-height</code>，后续的 <code>crop</code> 进行随机裁剪，其等价于使用随机偏移进行填充。</li><li><code>fill</code>：表示填充的数值，默认为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>，其仅在 <code>padding_mode=constant</code> 时有效。</li><li><code>padding_mode</code> 为设置填充模式，有如下几种模式：<ul><li><code>constant</code>：将填充为固定值 <code>fill</code>。</li><li><code>edge</code>：将根据边缘值进行填充。</li><li><code>reflect</code>：进行反射填充。</li><li><code>symmetric</code>：进行对称填充。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">img = torch.arange(<span class="number">9</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">print(img)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 1, 2],</span></span><br><span class="line"><span class="string">         [3, 4, 5],</span></span><br><span class="line"><span class="string">         [6, 7, 8]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomCrop(size=<span class="number">7</span>, padding=<span class="number">1</span>, pad_if_needed=<span class="literal">True</span>, fill=<span class="number">10</span>)</span><br><span class="line">print(t(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[10, 10, 10, 10, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10, 10, 10, 10, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10,  0,  1,  2, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10,  3,  4,  5, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10,  6,  7,  8, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10, 10, 10, 10, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10, 10, 10, 10, 10, 10, 10]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomCrop(size=<span class="number">7</span>, padding=<span class="number">2</span>, padding_mode=<span class="string">&#x27;edge&#x27;</span>)</span><br><span class="line">print(t(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 0, 0, 1, 2, 2, 2],</span></span><br><span class="line"><span class="string">         [0, 0, 0, 1, 2, 2, 2],</span></span><br><span class="line"><span class="string">         [0, 0, 0, 1, 2, 2, 2],</span></span><br><span class="line"><span class="string">         [3, 3, 3, 4, 5, 5, 5],</span></span><br><span class="line"><span class="string">         [6, 6, 6, 7, 8, 8, 8],</span></span><br><span class="line"><span class="string">         [6, 6, 6, 7, 8, 8, 8],</span></span><br><span class="line"><span class="string">         [6, 6, 6, 7, 8, 8, 8]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomCrop(size=<span class="number">7</span>, padding=<span class="number">2</span>, padding_mode=<span class="string">&#x27;reflect&#x27;</span>)</span><br><span class="line">print(t(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[8, 7, 6, 7, 8, 7, 6],</span></span><br><span class="line"><span class="string">         [5, 4, 3, 4, 5, 4, 3],</span></span><br><span class="line"><span class="string">         [2, 1, 0, 1, 2, 1, 0],</span></span><br><span class="line"><span class="string">         [5, 4, 3, 4, 5, 4, 3],</span></span><br><span class="line"><span class="string">         [8, 7, 6, 7, 8, 7, 6],</span></span><br><span class="line"><span class="string">         [5, 4, 3, 4, 5, 4, 3],</span></span><br><span class="line"><span class="string">         [2, 1, 0, 1, 2, 1, 0]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomCrop(size=<span class="number">7</span>, padding=<span class="number">2</span>, padding_mode=<span class="string">&#x27;symmetric&#x27;</span>)</span><br><span class="line">print(t(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[4, 3, 3, 4, 5, 5, 4],</span></span><br><span class="line"><span class="string">         [1, 0, 0, 1, 2, 2, 1],</span></span><br><span class="line"><span class="string">         [1, 0, 0, 1, 2, 2, 1],</span></span><br><span class="line"><span class="string">         [4, 3, 3, 4, 5, 5, 4],</span></span><br><span class="line"><span class="string">         [7, 6, 6, 7, 8, 8, 7],</span></span><br><span class="line"><span class="string">         [7, 6, 6, 7, 8, 8, 7],</span></span><br><span class="line"><span class="string">         [4, 3, 3, 4, 5, 5, 4]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://koumudai.github.io/posts/20211002000500.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000500.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.ConvertImageDtype</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:05:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:05:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:16:54" itemprop="dateModified" datetime="2021-10-27T09:16:54+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000500.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000500.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.7k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsconvertimagedtype"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsconvertimagedtype"></a> Pytorch.torchvision.transforms.ConvertImageDtype</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvertImageDtype</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert a tensor image to the given ``dtype`` and scale the values accordingly</span></span><br><span class="line"><span class="string">    This function does not support PIL Image.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dtype (torch.dtype): Desired data type of the output</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    note:</span></span><br><span class="line"><span class="string">        When converting from a smaller to a larger integer ``dtype`` the maximum values are **not** mapped exactly. If converted back and forth, this mismatch has no effect.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Raises:</span></span><br><span class="line"><span class="string">        RuntimeError: When trying to cast :class:`torch.float32` to :class:`torch.int32` or :class:`torch.int64` as well as for trying to cast :class:`torch.float64` to :class:`torch.int64`. These conversions might lead to overflow errors since the floating point ``dtype`` cannot store consecutive integers over the whole range of the integer ``dtype``.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>ConvertImageDtype</code> 将转变数据类型，可能会出现溢出的情况。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">img = torch.tensor([[[<span class="number">255</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">255</span>]], [[<span class="number">0</span>, <span class="number">255</span>], [<span class="number">0</span>, <span class="number">255</span>]], [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">255</span>, <span class="number">0</span>]]], dtype=torch.uint8)</span><br><span class="line">print(img)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[255,   0],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0, 255],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0,   0],</span></span><br><span class="line"><span class="string">         [255,   0]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t1 = transforms.ConvertImageDtype(torch.int32)</span><br><span class="line">print(t1(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[2139095040,          0],</span></span><br><span class="line"><span class="string">         [         0, 2139095040]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[         0, 2139095040],</span></span><br><span class="line"><span class="string">         [         0, 2139095040]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[         0,          0],</span></span><br><span class="line"><span class="string">         [2139095040,          0]]], dtype=torch.int32)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t2 = transforms.ConvertImageDtype(torch.uint8)</span><br><span class="line">print(t2(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[255,   0],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0, 255],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0,   0],</span></span><br><span class="line"><span class="string">         [255,   0]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><nav class="pagination"><a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/48/">48</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right" aria-label="下一页"></i></a></nav></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="智商为零的小白" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">智商为零的小白</p><div class="site-description" itemprop="description">生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">479</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">32</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">92</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/koumudai" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;koumudai" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:1979938740@qq.com" title="E-Mail → mailto:1979938740@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">智商为零的小白</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">1.5m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">22:31 小时</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css"><script>NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'rxJydM3QVoypB9apkSU3e9ML-gzGzoHsz',
      appKey     : 'NqXT8ScfaD1udoMiPk3NQ6MF',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});</script><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><canvas class="fireworks" style="position:fixed;left:0;top:0;z-index:1;pointer-events:none"></canvas><script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script><script type="text/javascript" src="/js/src/fireworks.js"></script></body></html>